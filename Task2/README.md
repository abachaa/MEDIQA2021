MEDIQA @ NAACL-BioNLP 2021 -- Task 2: Multi-answer summarization (MEDIQA-MAS)

https://sites.google.com/view/mediqa2021

## <h2>MEDIQA-MAS Dataset</h2>

**Training Data**

The [MEDIQA-AnS Dataset](https://www.nature.com/articles/s41597-020-00667-z) could be used for training. 

Participants can use available external resources such as existing [medical QA datasets](https://github.com/abachaa/Existing-Medical-QA-Datasets). 


**Validation and Test Sets**

The original answers are generated by the consumer health question answering system [CHiQA](https://chiqa.nlm.nih.gov/) which searches for answers from only trustworthy [medical information sources](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3119-4).  The summaries are manually created by medical experts. 

- The **validation set** contains 192 [answers](https://github.com/abachaa/MEDIQA2021/blob/main/Task2/Validation/MEDIQA2021_Task2_ValidationSet_Answers.xlsx) associated with 50 [questions](https://github.com/abachaa/MEDIQA2021/blob/main/Task2/Validation/MEDIQA2021_Task2_VAlidationSet_ShortQuestions.txt). Each question has at least two answers and their summaries.  For each question, we provide two types of summaries:  [extractive](https://github.com/abachaa/MEDIQA2021/blob/main/Task2/Validation/MEDIQA2021_Task2_ValidationSet_MultiExtractiveSummaries.txt) and [abstractive](https://github.com/abachaa/MEDIQA2021/blob/main/Task2/Validation/MEDIQA2021_Task2_ValidationSet_MultiAbstrativeSummaries.txt). We encourage the use of all types of summarization approaches (extractive, abstractive, and hybrid). We will also provide the **questions** in the official test set as they can be used as additional inputs for the summarization models.
 
- The **test set** contains 303 [answers](https://github.com/abachaa/MEDIQA2021/blob/main/Task2/Test/MEDIQA2021_Task2_MAS_TestSet_Answers.xlsx) associated with 80 [questions](https://github.com/abachaa/MEDIQA2021/blob/main/Task2/Test/MEDIQA2021_Task2_MAS_TestSet_shortQuestions.txt). For each test question, we provide two reference summaries: [extractive](https://github.com/abachaa/MEDIQA2021/blob/main/Task2/Test/MEDIQA2021_Task2_TestSet_MultiExtractiveSummaries.txt) and [abstractive](https://github.com/abachaa/MEDIQA2021/blob/main/Task2/Test/MEDIQA2021_Task2_TestSet_MultiAbstrativeSummaries.txt). ** In the official competiton, we used the abstractive reference summaries to evaluate the abstractive systems and the extractive summaries to evaluate the extractive systems (only extractive summaries were used on [AIcrowd-Task2](https://www.aicrowd.com/challenges/mediqa-2021/problems/mediqa-2021-multi-answer-summarization-mas/leaderboards?challenge_round_id=741)). 

## <h2>License</h2>
- The MEDIQA-MAS dataset is published under a Creative Commons Attribution 4.0 International License ([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)). Please cite our paper: 

         @inproceedings{mediqa-2021,
         title = "Overview of the {MEDIQA} 2021 Shared Task on Summarization in the Medical Domain",
         author = "Ben Abacha, Asma  and
         Mrabet, Yassine  and
         Zhang, Yuhao  and
         Shivade, Chaitanya  and
         Langlotz, Curtis  and
         Demner-Fushman, Dina",
         booktitle = "Proceedings of the 20th Workshop on Biomedical Language Processing",
         month = jun,
         year = "2021",
         publisher = "Association for Computational Linguistics",
         url = "https://aclanthology.org/2021.bionlp-1.8/",
         pages = "74--85",
         abstract = "The MEDIQA 2021 shared tasks at the BioNLP 2021 workshop addressed three tasks on summarization for medical text: (i) a question summarization task aimed at exploring new approaches to understanding complex real-world consumer health queries, (ii) a multi-answer summarization task that targeted aggregation of multiple relevant answers to a biomedical question into one concise and relevant answer, and (iii) a radiology report summarization task addressing the development of clinically relevant impressions from radiology report findings. Thirty-five teams participated in these shared tasks with sixteen working notes submitted (fifteen accepted) describing a wide variety of models developed and tested on the shared and external datasets. In this paper, we describe the tasks, the datasets, the models and techniques developed by various teams, the results of the evaluation, and a study of correlations among various summarization evaluation measures. We hope that these shared tasks will bring new research and insights in biomedical text summarization and evaluation."
          }
